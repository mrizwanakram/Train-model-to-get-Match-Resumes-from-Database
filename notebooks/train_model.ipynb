{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and prepare the data\n",
    "data = pd.read_csv('/home/rizwan/Desktop/Llama_model/resume-extractor/cleaned_resume_dataset.csv')\n",
    "\n",
    "# Check for missing values\n",
    "if data['pdf_name'].isnull().any() or data['skills'].isnull().any() or data['experience'].isnull().any():\n",
    "    raise ValueError(\"Data contains missing values.\")\n",
    "\n",
    "# Prepare features and labels\n",
    "X = data['pdf_name'].astype(str)\n",
    "y_skills = data['skills'].astype(str)\n",
    "y_experience = data['experience'].astype(str)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder_skills = LabelEncoder()\n",
    "label_encoder_experience = LabelEncoder()\n",
    "y_skills_encoded = label_encoder_skills.fit_transform(y_skills)\n",
    "y_experience_encoded = label_encoder_experience.fit_transform(y_experience)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train_skills, y_val_skills, y_train_experience, y_val_experience = train_test_split(\n",
    "    X, y_skills_encoded, y_experience_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "maxlen = 100  # Maximum length of sequences\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=maxlen)\n",
    "X_val_padded = pad_sequences(X_val_seq, maxlen=maxlen)\n",
    "\n",
    "# Confirm shapes and types\n",
    "print(\"X_train_padded shape:\", X_train_padded.shape)\n",
    "print(\"X_val_padded shape:\", X_val_padded.shape)\n",
    "print(type(X_train_padded), type(X_val_padded))  # Ensure they are numpy arrays\n",
    "\n",
    "# Define model architecture\n",
    "input_layer = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128)(input_layer)\n",
    "\n",
    "# Check embedding output shape\n",
    "print(\"Embedding output shape:\", embedding_layer.shape)  # Expected: (None, maxlen, 128)\n",
    "\n",
    "# LSTM layer\n",
    "lstm_layer = Bidirectional(LSTM(64, return_sequences=False))(embedding_layer)\n",
    "\n",
    "# Check LSTM output shape\n",
    "print(\"LSTM output shape:\", lstm_layer.shape)  # Expected: (None, 128)\n",
    "\n",
    "# Output layers\n",
    "output_skills = Dense(len(label_encoder_skills.classes_), activation='softmax', name='skills_output')(lstm_layer)\n",
    "output_experience = Dense(len(label_encoder_experience.classes_), activation='softmax', name='experience_output')(lstm_layer)\n",
    "\n",
    "# Create and compile the model\n",
    "model = Model(inputs=input_layer, outputs=[output_skills, output_experience])\n",
    "model.compile(\n",
    "    loss={\n",
    "        'skills_output': 'sparse_categorical_crossentropy',\n",
    "        'experience_output': 'sparse_categorical_crossentropy'\n",
    "    },\n",
    "    optimizer='adam',\n",
    "    metrics={\n",
    "        'skills_output': 'accuracy',\n",
    "        'experience_output': 'accuracy'  # Add metrics for both outputs\n",
    "    }\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_padded, [y_train_skills, y_train_experience], \n",
    "          validation_data=(X_val_padded, [y_val_skills, y_val_experience]),\n",
    "          epochs=50, \n",
    "          batch_size=32)\n",
    "\n",
    "# Save the model\n",
    "model.save('resume_model.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# If NLTK data is not downloaded, run this once\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "This dataset contains resume information extracted from various PDFs, and it will be used for the task of cleaning and training a machine learning model. The dataset includes the following columns:\n",
    "\n",
    "- **pdf_name**: The name of the resume PDF file.\n",
    "- **skills**: The skills section from the resume, containing details like technical expertise, programming languages, tools, and relevant skill sets.\n",
    "- **experience**: The professional experience section, which lists past job titles, companies, and roles held, along with a brief description of responsibilities and accomplishments.\n",
    "                                                     |\n",
    "\n",
    "### Goals\n",
    "\n",
    "1. **Data Cleaning**: The dataset requires preprocessing to clean up any inconsistencies, special characters, and formatting issues from the extracted text.\n",
    "2. **Feature Extraction**: Skills and experience data will be processed to extract key features relevant for model training, such as skill tags and role hierarchies.\n",
    "3. **Model Training**: The cleaned and structured dataset will be used to train a machine learning model to classify resumes, predict skill sets, or match job profiles based on the resume data.\n",
    "\n",
    "This dataset provides a rich source of information that combines natural language text from resumes and can be leveraged for various machine learning tasks like skill extraction, experience classification, and job matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>skills</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfred_Huynh_Resume.pdf</td>\n",
       "      <td>**\\n\\n1. **Database Development**\\n\\t* Oracle ...</td>\n",
       "      <td>**\\n\\n**1. Database Developer, ZP Group (Clien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obafemi_Oshin_Resume.pdf</td>\n",
       "      <td>**\\n\\n1. Proficient languages:\\n\\t* Java\\n\\t* ...</td>\n",
       "      <td>**\\n\\n1. **Software Engineer (Freelance)**, Ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lawrence_Chopp_Resume.pdf</td>\n",
       "      <td>**\\n\\n* Project Management\\n* Microsoft Office...</td>\n",
       "      <td>**\\n\\n**Project Manager - Population Health (J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Syed_Akhtar_Resume.pdf</td>\n",
       "      <td>**\\n\\n1. Programming languages:\\n\\t* JavaScrip...</td>\n",
       "      <td>**\\n\\n1. **Senior Full-Stack Developer, Accent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prashamsha_Pathak_Resume.pdf</td>\n",
       "      <td>**\\n\\n1. Power BI Dashboards development\\n2. D...</td>\n",
       "      <td>**\\n\\n1. **SQL Server Developer**, Chitwan Hos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pdf_name  \\\n",
       "0       Alfred_Huynh_Resume.pdf   \n",
       "1      Obafemi_Oshin_Resume.pdf   \n",
       "2     Lawrence_Chopp_Resume.pdf   \n",
       "3        Syed_Akhtar_Resume.pdf   \n",
       "4  Prashamsha_Pathak_Resume.pdf   \n",
       "\n",
       "                                              skills  \\\n",
       "0  **\\n\\n1. **Database Development**\\n\\t* Oracle ...   \n",
       "1  **\\n\\n1. Proficient languages:\\n\\t* Java\\n\\t* ...   \n",
       "2  **\\n\\n* Project Management\\n* Microsoft Office...   \n",
       "3  **\\n\\n1. Programming languages:\\n\\t* JavaScrip...   \n",
       "4  **\\n\\n1. Power BI Dashboards development\\n2. D...   \n",
       "\n",
       "                                          experience  \n",
       "0  **\\n\\n**1. Database Developer, ZP Group (Clien...  \n",
       "1  **\\n\\n1. **Software Engineer (Freelance)**, Ke...  \n",
       "2  **\\n\\n**Project Manager - Population Health (J...  \n",
       "3  **\\n\\n1. **Senior Full-Stack Developer, Accent...  \n",
       "4  **\\n\\n1. **SQL Server Developer**, Chitwan Hos...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"extracted_data_folder_1.csv\")\n",
    "\n",
    "# Display first few rows to understand structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf_name        0\n",
      "skills         10\n",
      "experience    154\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Drop rows with missing skills or experience\n",
    "df_cleaned = df.dropna(subset=['skills', 'experience'])\n",
    "\n",
    "# # Option 2: Fill missing values with empty strings (if you don't want to drop rows)\n",
    "# df['skills'].fillna(\"\", inplace=True)\n",
    "# df['experience'].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>skills</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfred_Huynh_Resume.pdf</td>\n",
       "      <td>**\\n\\n1. **Database Development**\\n\\t* Oracle ...</td>\n",
       "      <td>**\\n\\n**1. Database Developer, ZP Group (Clien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obafemi_Oshin_Resume.pdf</td>\n",
       "      <td>**\\n\\n1. Proficient languages:\\n\\t* Java\\n\\t* ...</td>\n",
       "      <td>**\\n\\n1. **Software Engineer (Freelance)**, Ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lawrence_Chopp_Resume.pdf</td>\n",
       "      <td>**\\n\\n* Project Management\\n* Microsoft Office...</td>\n",
       "      <td>**\\n\\n**Project Manager - Population Health (J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Syed_Akhtar_Resume.pdf</td>\n",
       "      <td>**\\n\\n1. Programming languages:\\n\\t* JavaScrip...</td>\n",
       "      <td>**\\n\\n1. **Senior Full-Stack Developer, Accent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prashamsha_Pathak_Resume.pdf</td>\n",
       "      <td>**\\n\\n1. Power BI Dashboards development\\n2. D...</td>\n",
       "      <td>**\\n\\n1. **SQL Server Developer**, Chitwan Hos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pdf_name  \\\n",
       "0       Alfred_Huynh_Resume.pdf   \n",
       "1      Obafemi_Oshin_Resume.pdf   \n",
       "2     Lawrence_Chopp_Resume.pdf   \n",
       "3        Syed_Akhtar_Resume.pdf   \n",
       "4  Prashamsha_Pathak_Resume.pdf   \n",
       "\n",
       "                                              skills  \\\n",
       "0  **\\n\\n1. **Database Development**\\n\\t* Oracle ...   \n",
       "1  **\\n\\n1. Proficient languages:\\n\\t* Java\\n\\t* ...   \n",
       "2  **\\n\\n* Project Management\\n* Microsoft Office...   \n",
       "3  **\\n\\n1. Programming languages:\\n\\t* JavaScrip...   \n",
       "4  **\\n\\n1. Power BI Dashboards development\\n2. D...   \n",
       "\n",
       "                                          experience  \n",
       "0  **\\n\\n**1. Database Developer, ZP Group (Clien...  \n",
       "1  **\\n\\n1. **Software Engineer (Freelance)**, Ke...  \n",
       "2  **\\n\\n**Project Manager - Population Health (J...  \n",
       "3  **\\n\\n1. **Senior Full-Stack Developer, Accent...  \n",
       "4  **\\n\\n1. **SQL Server Developer**, Chitwan Hos...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate rows (if any)\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Text Cleaning - Remove Special Characters, URLs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>skills</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfred_Huynh_Resume.pdf</td>\n",
       "      <td>database development oracle sql oracle plsql m...</td>\n",
       "      <td>database developer zp group client adtalem glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obafemi_Oshin_Resume.pdf</td>\n",
       "      <td>proficient languages java javascript python c ...</td>\n",
       "      <td>software engineer freelance keller williams re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lawrence_Chopp_Resume.pdf</td>\n",
       "      <td>project management microsoft office budget man...</td>\n",
       "      <td>project manager population health january pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Syed_Akhtar_Resume.pdf</td>\n",
       "      <td>programming languages javascript python fronte...</td>\n",
       "      <td>senior fullstack developer accenture remote se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prashamsha_Pathak_Resume.pdf</td>\n",
       "      <td>power bi dashboards development dax language i...</td>\n",
       "      <td>sql server developer chitwan hospital bharatpu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pdf_name  \\\n",
       "0       Alfred_Huynh_Resume.pdf   \n",
       "1      Obafemi_Oshin_Resume.pdf   \n",
       "2     Lawrence_Chopp_Resume.pdf   \n",
       "3        Syed_Akhtar_Resume.pdf   \n",
       "4  Prashamsha_Pathak_Resume.pdf   \n",
       "\n",
       "                                              skills  \\\n",
       "0  database development oracle sql oracle plsql m...   \n",
       "1  proficient languages java javascript python c ...   \n",
       "2  project management microsoft office budget man...   \n",
       "3  programming languages javascript python fronte...   \n",
       "4  power bi dashboards development dax language i...   \n",
       "\n",
       "                                          experience  \n",
       "0  database developer zp group client adtalem glo...  \n",
       "1  software engineer freelance keller williams re...  \n",
       "2  project manager population health january pres...  \n",
       "3  senior fullstack developer accenture remote se...  \n",
       "4  sql server developer chitwan hospital bharatpu...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove special characters, numbers, and punctuations\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove newline characters and backslashes\n",
    "    text = text.replace('\\n', '').replace('\\\\', '')\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply cleaning function to skills and experience\n",
    "df_cleaned['skills'] = df_cleaned['skills'].apply(clean_text)\n",
    "df_cleaned['experience'] = df_cleaned['experience'].apply(clean_text)\n",
    "\n",
    "# Display a few cleaned rows to verify\n",
    "df_cleaned[['pdf_name', 'skills', 'experience']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>skills</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfred_Huynh_Resume.pdf</td>\n",
       "      <td>database development oracle sql oracle plsql m...</td>\n",
       "      <td>database developer zp group client adtalem glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obafemi_Oshin_Resume.pdf</td>\n",
       "      <td>proficient languages java javascript python c ...</td>\n",
       "      <td>software engineer freelance keller williams re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lawrence_Chopp_Resume.pdf</td>\n",
       "      <td>project management microsoft office budget man...</td>\n",
       "      <td>project manager population health january pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Syed_Akhtar_Resume.pdf</td>\n",
       "      <td>programming languages javascript python fronte...</td>\n",
       "      <td>senior fullstack developer accenture remote se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prashamsha_Pathak_Resume.pdf</td>\n",
       "      <td>power bi dashboards development dax language i...</td>\n",
       "      <td>sql server developer chitwan hospital bharatpu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pdf_name  \\\n",
       "0       Alfred_Huynh_Resume.pdf   \n",
       "1      Obafemi_Oshin_Resume.pdf   \n",
       "2     Lawrence_Chopp_Resume.pdf   \n",
       "3        Syed_Akhtar_Resume.pdf   \n",
       "4  Prashamsha_Pathak_Resume.pdf   \n",
       "\n",
       "                                              skills  \\\n",
       "0  database development oracle sql oracle plsql m...   \n",
       "1  proficient languages java javascript python c ...   \n",
       "2  project management microsoft office budget man...   \n",
       "3  programming languages javascript python fronte...   \n",
       "4  power bi dashboards development dax language i...   \n",
       "\n",
       "                                          experience  \n",
       "0  database developer zp group client adtalem glo...  \n",
       "1  software engineer freelance keller williams re...  \n",
       "2  project manager population health january pres...  \n",
       "3  senior fullstack developer accenture remote se...  \n",
       "4  sql server developer chitwan hospital bharatpu...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "# Apply stopword removal to skills and experience\n",
    "df_cleaned['skills'] = df_cleaned['skills'].apply(remove_stopwords)\n",
    "df_cleaned['experience'] = df_cleaned['experience'].apply(remove_stopwords)\n",
    "\n",
    "# Display cleaned text\n",
    "df_cleaned[['pdf_name', 'skills', 'experience']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Remove Short or Irrelevant Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>skills</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfred_Huynh_Resume.pdf</td>\n",
       "      <td>database development oracle sql oracle plsql m...</td>\n",
       "      <td>database developer zp group client adtalem glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obafemi_Oshin_Resume.pdf</td>\n",
       "      <td>proficient languages java javascript python c ...</td>\n",
       "      <td>software engineer freelance keller williams re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lawrence_Chopp_Resume.pdf</td>\n",
       "      <td>project management microsoft office budget man...</td>\n",
       "      <td>project manager population health january pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Syed_Akhtar_Resume.pdf</td>\n",
       "      <td>programming languages javascript python fronte...</td>\n",
       "      <td>senior fullstack developer accenture remote se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prashamsha_Pathak_Resume.pdf</td>\n",
       "      <td>power bi dashboards development dax language i...</td>\n",
       "      <td>sql server developer chitwan hospital bharatpu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pdf_name  \\\n",
       "0       Alfred_Huynh_Resume.pdf   \n",
       "1      Obafemi_Oshin_Resume.pdf   \n",
       "2     Lawrence_Chopp_Resume.pdf   \n",
       "3        Syed_Akhtar_Resume.pdf   \n",
       "4  Prashamsha_Pathak_Resume.pdf   \n",
       "\n",
       "                                              skills  \\\n",
       "0  database development oracle sql oracle plsql m...   \n",
       "1  proficient languages java javascript python c ...   \n",
       "2  project management microsoft office budget man...   \n",
       "3  programming languages javascript python fronte...   \n",
       "4  power bi dashboards development dax language i...   \n",
       "\n",
       "                                          experience  \n",
       "0  database developer zp group client adtalem glo...  \n",
       "1  software engineer freelance keller williams re...  \n",
       "2  project manager population health january pres...  \n",
       "3  senior fullstack developer accenture remote se...  \n",
       "4  sql server developer chitwan hospital bharatpu...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out rows with less than 3 words in skills or experience\n",
    "df_cleaned = df_cleaned[df_cleaned['skills'].apply(lambda x: len(x.split()) > 2)]\n",
    "df_cleaned = df_cleaned[df_cleaned['experience'].apply(lambda x: len(x.split()) > 5)]\n",
    "\n",
    "# Display the final cleaned dataframe\n",
    "df_cleaned[['pdf_name', 'skills', 'experience']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Save the Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataframe to a new CSV\n",
    "df_cleaned.to_csv(\"cleaned_resume_dataset.csv\", index=False)\n",
    "\n",
    "# Verify the file is saved\n",
    "print(\"Cleaned dataset saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Laibraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Bidirectional, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/rizwan/Desktop/Django/model train/cleaned_resume_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['pdf_name'] \n",
    "y_skills = data['skills']  \n",
    "y_experience = data['experience'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_skills = LabelEncoder()\n",
    "label_encoder_experience = LabelEncoder()\n",
    "y_skills_encoded = label_encoder_skills.fit_transform(y_skills)\n",
    "y_experience_encoded = label_encoder_experience.fit_transform(y_experience)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_val, y_train_skills, y_val_skills, y_train_experience, y_val_experience = train_test_split(\n",
    "    X, y_skills_encoded, y_experience_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tokenize the PDF names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pad the sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Define the model for multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizwan/Desktop/Django/model train/env/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "object __array__ method not producing an array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m input_layer \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(maxlen,))\n\u001b[1;32m      5\u001b[0m embedding_layer \u001b[38;5;241m=\u001b[39m Embedding(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mword_index) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, input_length\u001b[38;5;241m=\u001b[39mmaxlen)(input_layer)\n\u001b[0;32m----> 6\u001b[0m lstm_layer \u001b[38;5;241m=\u001b[39m \u001b[43mBidirectional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_layer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Django/model train/env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/Django/model train/env/lib/python3.10/site-packages/keras/src/backend/tensorflow/numpy.py:2414\u001b[0m, in \u001b[0;36mtranspose\u001b[0;34m(x, axes)\u001b[0m\n\u001b[1;32m   2412\u001b[0m     output\u001b[38;5;241m.\u001b[39mset_shape(compute_transpose_output_shape(x\u001b[38;5;241m.\u001b[39mshape, axes))\n\u001b[1;32m   2413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m-> 2414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: object __array__ method not producing an array"
     ]
    }
   ],
   "source": [
    "maxlen = 100  \n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=maxlen)\n",
    "X_val_padded = pad_sequences(X_val_seq, maxlen=maxlen)\n",
    "input_layer = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=maxlen)(input_layer)\n",
    "lstm_layer = Bidirectional(LSTM(64, return_sequences=False))(embedding_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step - experience_output_accuracy: 0.0000e+00 - experience_output_loss: 6.8165 - loss: 13.6324 - skills_output_accuracy: 0.0000e+00 - skills_output_loss: 6.8159 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 6.8121 - val_loss: 13.6202 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 6.8082\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - experience_output_accuracy: 0.0000e+00 - experience_output_loss: 6.8134 - loss: 13.6275 - skills_output_accuracy: 0.0049 - skills_output_loss: 6.8140 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 6.8600 - val_loss: 13.7179 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 6.8582\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - experience_output_accuracy: 0.0047 - experience_output_loss: 6.7931 - loss: 13.5865 - skills_output_accuracy: 1.7381e-04 - skills_output_loss: 6.7934 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 7.5703 - val_loss: 15.1319 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 7.5612\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - experience_output_accuracy: 0.0025 - experience_output_loss: 6.7379 - loss: 13.4761 - skills_output_accuracy: 0.0014 - skills_output_loss: 6.7382 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 7.1669 - val_loss: 14.3247 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 7.1587\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - experience_output_accuracy: 0.0017 - experience_output_loss: 6.7324 - loss: 13.4654 - skills_output_accuracy: 0.0022 - skills_output_loss: 6.7329 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 8.4557 - val_loss: 16.8886 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 8.4337\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - experience_output_accuracy: 0.0000e+00 - experience_output_loss: 6.6412 - loss: 13.2779 - skills_output_accuracy: 0.0000e+00 - skills_output_loss: 6.6368 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 8.9086 - val_loss: 17.7999 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 8.8926\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - experience_output_accuracy: 7.7957e-04 - experience_output_loss: 6.6082 - loss: 13.2185 - skills_output_accuracy: 0.0000e+00 - skills_output_loss: 6.6106 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 9.2108 - val_loss: 18.4034 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 9.1942\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - experience_output_accuracy: 5.1838e-04 - experience_output_loss: 6.5899 - loss: 13.1833 - skills_output_accuracy: 0.0015 - skills_output_loss: 6.5936 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 9.3476 - val_loss: 18.6783 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 9.3312\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - experience_output_accuracy: 0.0042 - experience_output_loss: 6.5681 - loss: 13.1378 - skills_output_accuracy: 0.0077 - skills_output_loss: 6.5698 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 9.8342 - val_loss: 19.6494 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 9.8167\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - experience_output_accuracy: 0.0152 - experience_output_loss: 6.4724 - loss: 12.9446 - skills_output_accuracy: 0.0155 - skills_output_loss: 6.4721 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 10.1796 - val_loss: 20.3265 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 10.1511\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - experience_output_accuracy: 0.0430 - experience_output_loss: 6.2194 - loss: 12.4336 - skills_output_accuracy: 0.0486 - skills_output_loss: 6.2144 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 10.6842 - val_loss: 21.2925 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 10.6174\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - experience_output_accuracy: 0.1290 - experience_output_loss: 5.8580 - loss: 11.7214 - skills_output_accuracy: 0.0939 - skills_output_loss: 5.8633 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 10.6279 - val_loss: 21.2096 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 10.5940\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - experience_output_accuracy: 0.2385 - experience_output_loss: 5.4940 - loss: 10.9916 - skills_output_accuracy: 0.2015 - skills_output_loss: 5.4977 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 10.8895 - val_loss: 21.7454 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 10.8662\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - experience_output_accuracy: 0.3872 - experience_output_loss: 5.1528 - loss: 10.3024 - skills_output_accuracy: 0.3721 - skills_output_loss: 5.1496 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 11.5732 - val_loss: 23.0938 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 11.5308\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - experience_output_accuracy: 0.5552 - experience_output_loss: 4.8137 - loss: 9.6240 - skills_output_accuracy: 0.5650 - skills_output_loss: 4.8104 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 11.4089 - val_loss: 22.7725 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 11.3755\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - experience_output_accuracy: 0.7621 - experience_output_loss: 4.4571 - loss: 8.9115 - skills_output_accuracy: 0.7650 - skills_output_loss: 4.4545 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 11.6168 - val_loss: 23.1940 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 11.5873\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - experience_output_accuracy: 0.8453 - experience_output_loss: 4.1475 - loss: 8.2922 - skills_output_accuracy: 0.8556 - skills_output_loss: 4.1447 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 11.7407 - val_loss: 23.4383 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 11.7083\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - experience_output_accuracy: 0.9218 - experience_output_loss: 3.8551 - loss: 7.7090 - skills_output_accuracy: 0.8949 - skills_output_loss: 3.8540 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 11.7830 - val_loss: 23.5163 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 11.7439\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - experience_output_accuracy: 0.9616 - experience_output_loss: 3.5616 - loss: 7.1205 - skills_output_accuracy: 0.9569 - skills_output_loss: 3.5592 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 11.7592 - val_loss: 23.4687 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 11.7199\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - experience_output_accuracy: 0.9747 - experience_output_loss: 3.3034 - loss: 6.5939 - skills_output_accuracy: 0.9758 - skills_output_loss: 3.2907 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 11.9687 - val_loss: 23.8906 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 11.9327\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - experience_output_accuracy: 0.9798 - experience_output_loss: 3.0318 - loss: 6.0744 - skills_output_accuracy: 0.9773 - skills_output_loss: 3.0427 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 11.9769 - val_loss: 23.9060 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 11.9384\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - experience_output_accuracy: 0.9811 - experience_output_loss: 2.7980 - loss: 5.5973 - skills_output_accuracy: 0.9896 - skills_output_loss: 2.7995 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 11.9719 - val_loss: 23.9003 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 11.9384\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - experience_output_accuracy: 0.9947 - experience_output_loss: 2.5892 - loss: 5.1807 - skills_output_accuracy: 0.9876 - skills_output_loss: 2.5915 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.2549 - val_loss: 24.4542 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.2096\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - experience_output_accuracy: 0.9940 - experience_output_loss: 2.3386 - loss: 4.6781 - skills_output_accuracy: 0.9874 - skills_output_loss: 2.3395 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.2427 - val_loss: 24.4379 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.2044\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - experience_output_accuracy: 0.9991 - experience_output_loss: 2.1619 - loss: 4.3265 - skills_output_accuracy: 0.9977 - skills_output_loss: 2.1646 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.3968 - val_loss: 24.7437 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.3569\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - experience_output_accuracy: 0.9994 - experience_output_loss: 1.9768 - loss: 3.9550 - skills_output_accuracy: 0.9957 - skills_output_loss: 1.9782 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.3996 - val_loss: 24.7536 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.3625\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - experience_output_accuracy: 0.9989 - experience_output_loss: 1.7910 - loss: 3.5799 - skills_output_accuracy: 0.9953 - skills_output_loss: 1.7889 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.4789 - val_loss: 24.9095 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.4402\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - experience_output_accuracy: 0.9998 - experience_output_loss: 1.6315 - loss: 3.2694 - skills_output_accuracy: 0.9998 - skills_output_loss: 1.6379 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.4139 - val_loss: 24.7830 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.3790\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 1.4978 - loss: 3.0004 - skills_output_accuracy: 1.0000 - skills_output_loss: 1.5023 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.5142 - val_loss: 24.9768 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.4736\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 1.3445 - loss: 2.6879 - skills_output_accuracy: 1.0000 - skills_output_loss: 1.3435 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.5816 - val_loss: 25.1178 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.5453\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 1.2332 - loss: 2.4655 - skills_output_accuracy: 1.0000 - skills_output_loss: 1.2325 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.6716 - val_loss: 25.3011 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.6373\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 1.1119 - loss: 2.2255 - skills_output_accuracy: 1.0000 - skills_output_loss: 1.1138 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.6741 - val_loss: 25.3043 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.6395\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 1.0230 - loss: 2.0457 - skills_output_accuracy: 1.0000 - skills_output_loss: 1.0227 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.7231 - val_loss: 25.4021 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.6886\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.9299 - loss: 1.8599 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.9301 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.8478 - val_loss: 25.6516 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.8115\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.8421 - loss: 1.6788 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.8368 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.8078 - val_loss: 25.5727 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.7728\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.7802 - loss: 1.5626 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.7824 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.8111 - val_loss: 25.5810 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.7786\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.7088 - loss: 1.4214 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.7126 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.9318 - val_loss: 25.8221 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.8977\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.6605 - loss: 1.3184 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.6578 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.9047 - val_loss: 25.7665 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.8700\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.6117 - loss: 1.2235 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.6119 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.9760 - val_loss: 25.9073 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.9390\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.5530 - loss: 1.1070 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.5540 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.9715 - val_loss: 25.8999 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.9368\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.5173 - loss: 1.0354 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.5181 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 12.9964 - val_loss: 25.9511 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 12.9618\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.4807 - loss: 0.9629 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.4822 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 13.0749 - val_loss: 26.1066 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 13.0395\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.4573 - loss: 0.9164 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.4590 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 13.1198 - val_loss: 26.1978 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 13.0849\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.4234 - loss: 0.8469 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.4236 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 13.1379 - val_loss: 26.2333 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 13.1023\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.4034 - loss: 0.8069 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.4033 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 13.1707 - val_loss: 26.3008 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 13.1368\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.3713 - loss: 0.7426 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.3714 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 13.2159 - val_loss: 26.3924 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 13.1832\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.3548 - loss: 0.7099 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.3552 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 13.1904 - val_loss: 26.3380 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 13.1539\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.3345 - loss: 0.6684 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.3338 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 13.2591 - val_loss: 26.4783 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 13.2258\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.3121 - loss: 0.6243 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.3121 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 13.2896 - val_loss: 26.5356 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 13.2529\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - experience_output_accuracy: 1.0000 - experience_output_loss: 0.2996 - loss: 0.5999 - skills_output_accuracy: 1.0000 - skills_output_loss: 0.3003 - val_experience_output_accuracy: 0.0000e+00 - val_experience_output_loss: 13.3162 - val_loss: 26.5892 - val_skills_output_accuracy: 0.0000e+00 - val_skills_output_loss: 13.2798\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Output layers\n",
    "output_skills = Dense(len(label_encoder_skills.classes_), activation='softmax', name='skills_output')(lstm_layer)\n",
    "output_experience = Dense(len(label_encoder_experience.classes_), activation='softmax', name='experience_output')(lstm_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[output_skills, output_experience])\n",
    "\n",
    "# Compile the model with metrics for both outputs\n",
    "model.compile(\n",
    "    loss={'skills_output': 'sparse_categorical_crossentropy', 'experience_output': 'sparse_categorical_crossentropy'},\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', 'accuracy']  # Provide accuracy for both outputs\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_padded,\n",
    "    [y_train_skills, y_train_experience],\n",
    "    validation_data=(X_val_padded, [y_val_skills, y_val_experience]),\n",
    "    epochs=50,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Save the model after training\n",
    "model.save('resume_model.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 102\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Example usage for testing\u001b[39;00m\n\u001b[1;32m    101\u001b[0m job_description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcyber security\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 102\u001b[0m top_matching_resumes \u001b[38;5;241m=\u001b[39m match_resumes_with_job_description(job_description, \u001b[43mdata\u001b[49m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m top_matching_resumes:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('resume_model.keras')\n",
    "\n",
    "# Initialize the Tokenizer and fit it on your training data\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Load the original training dataset to fit the tokenizer\n",
    "# Replace 'path/to/your/training/data.csv' with the actual path\n",
    "original_training_data = pd.read_csv('cleaned_resume_dataset.csv')\n",
    "tokenizer.fit_on_texts(original_training_data['pdf_name'])  # Assuming 'pdf_name' contains the text data\n",
    "\n",
    "# Initialize Label Encoders\n",
    "label_encoder_skills = LabelEncoder()\n",
    "label_encoder_experience = LabelEncoder()\n",
    "\n",
    "# Fit the Label Encoders\n",
    "# Replace with your actual skill and experience columns\n",
    "label_encoder_skills.fit(original_training_data['skills'])\n",
    "label_encoder_experience.fit(original_training_data['experience'])\n",
    "\n",
    "# Function to preprocess the resume text for the model\n",
    "def preprocess_for_model(resume_text):\n",
    "    resume_seq = tokenizer.texts_to_sequences([resume_text])\n",
    "    padded_seq = pad_sequences(resume_seq, maxlen=100)  # Adjust maxlen based on your model\n",
    "    # Removed print statement\n",
    "    return padded_seq\n",
    "\n",
    "# Function to predict skills and experience using the trained model\n",
    "def predict_skills_and_experience(resume_text):\n",
    "    resume_padded = preprocess_for_model(resume_text)\n",
    "    \n",
    "    try:\n",
    "        # Use the model to predict\n",
    "        skills_pred, experience_pred = model.predict(resume_padded)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")  # Debugging line\n",
    "        return None, None\n",
    "\n",
    "    # Get the predicted classes\n",
    "    predicted_skills = np.argmax(skills_pred, axis=1)[0]\n",
    "    predicted_experience = np.argmax(experience_pred, axis=1)[0]\n",
    "\n",
    "    # Decode the predictions to get actual skill and experience values\n",
    "    decoded_skill = label_encoder_skills.inverse_transform([predicted_skills])[0]\n",
    "    decoded_experience = label_encoder_experience.inverse_transform([predicted_experience])[0]\n",
    "\n",
    "    return decoded_skill, decoded_experience\n",
    "\n",
    "# Function to preprocess job descriptions\n",
    "def preprocess_text(text):\n",
    "    return text.lower()  # Basic preprocessing\n",
    "\n",
    "# Function to match resumes with the provided job description\n",
    "def match_resumes_with_job_description(job_description, resumes_df):\n",
    "    job_description_cleaned = preprocess_text(job_description)\n",
    "    job_description_words = job_description_cleaned.split()\n",
    "    \n",
    "    match_results = []\n",
    "    \n",
    "    for index, row in resumes_df.iterrows():\n",
    "        resume_name = row['pdf_name']\n",
    "        resume_text = f\"{row['skills']} {row['experience']}\"  # Combine skills and experience\n",
    "        \n",
    "        # Predict skills and experience using the model\n",
    "        predicted_skill, predicted_experience = predict_skills_and_experience(resume_text)\n",
    "        \n",
    "        if predicted_skill is None or predicted_experience is None:\n",
    "            print(f\"Skipping {resume_name} due to prediction error.\")  # Debugging line\n",
    "            continue\n",
    "        \n",
    "        # Check for exact match for single words\n",
    "        if len(job_description_words) == 1:\n",
    "            single_word = job_description_words[0]\n",
    "            if single_word in predicted_skill.lower() or single_word in predicted_experience.lower():\n",
    "                match_results.append({\n",
    "                    \"resume\": resume_name,\n",
    "                    \"match_percentage\": 100,\n",
    "                })\n",
    "        \n",
    "        # Fuzzy matching for multiple words\n",
    "        else:\n",
    "            match_percentage = fuzz.token_set_ratio(job_description_cleaned, resume_text)\n",
    "            match_results.append({\n",
    "                \"resume\": resume_name,\n",
    "                \"match_percentage\": match_percentage,\n",
    "            })\n",
    "    \n",
    "    # Sort results by match percentage and return top 5\n",
    "    sorted_results = sorted(match_results, key=lambda x: x[\"match_percentage\"], reverse=True)[:5]\n",
    "    return sorted_results\n",
    "\n",
    "# Example usage for testing\n",
    "job_description = \"cyber security\"\n",
    "top_matching_resumes = match_resumes_with_job_description(job_description, data)\n",
    "\n",
    "# Print results\n",
    "if top_matching_resumes:\n",
    "    print(\"Top matching resumes:\")\n",
    "    for result in top_matching_resumes:\n",
    "        print(f\"{result['resume']}: {result['match_percentage']}% matching skills/experience\")\n",
    "else:\n",
    "    print(\"No matching resumes found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
